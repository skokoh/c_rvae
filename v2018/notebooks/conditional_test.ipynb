{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model.vae import conditional_cnn_vae_rnn\n",
    "from util.miditools import piano_roll_to_pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Setting up constants and loading the data\n",
    "##################################################################\n",
    "\n",
    "snapshot_interval = 200\n",
    "log_interval = 50\n",
    "\n",
    "checkpoint_file = './tfmodel/exp-pmde-iter-%s.tfmodel'\n",
    "mudb_file = '/home/eko/winter2018/Piano-midi.de/preprocessing/mudb_train.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-51a282ab30e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnote_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train_data = np.load(mudb_file)\n",
    "\n",
    "fs = train_data['fs']\n",
    "num_timesteps = int(fs)\n",
    "bars = train_data['bars']\n",
    "np.random.shuffle(bars)\n",
    "note_range = int(bars.shape[2])\n",
    "T = int(train_data['T'])\n",
    "num_batches = int(bars.shape[0])\n",
    "\n",
    "height = num_timesteps\n",
    "width = note_range\n",
    "n_visible = note_range * num_timesteps\n",
    "n_epochs = 10\n",
    "\n",
    "z_dim = 500\n",
    "X_dim = width * height\n",
    "n_hidden = z_dim\n",
    "h_dim = z_dim\n",
    "\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "audio_sr = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Loading the model\n",
    "##################################################################\n",
    "with tf.name_scope('placeholders'):\n",
    "    z = tf.placeholder(tf.float32, shape=[None, z_dim], name=\"Generated_noise\")\n",
    "    z_rnn_samples = tf.placeholder(tf.float32, shape=[None, height, width, 1], name=\"Generated_midi_input\")\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width, 1], name=\"Training_samples\")\n",
    "    kl_annealing = tf.placeholder(tf.float32, name=\"KL_annealing_multiplier\")\n",
    "\n",
    "model = conditional_cnn_vae_rnn(X, z, z_rnn_samples, X_dim, z_dim=z_dim, h_dim=h_dim, initializer=initializer, keep_prob=0.6)\n",
    "\n",
    "X_samples, out_samples, logits = (model['X_samples'], model['out_samples'], model['logits'])\n",
    "z_mu, z_logvar = (model['z_mu'], model['z_logvar'])\n",
    "\n",
    "##################################################################\n",
    "# Losses\n",
    "##################################################################\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    X_labels = tf.reshape(X, [-1, width*height])\n",
    "\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X_labels), 1)\n",
    "    with tf.name_scope(\"kl_divergence\"):\n",
    "        kl_loss = kl_annealing * 0.5 * tf.reduce_sum(tf.square(z_mu) + tf.square(z_logvar) - tf.log(tf.square(z_logvar)) - 1,1) \n",
    "    \n",
    "    loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "##################################################################\n",
    "# Optimizer\n",
    "##################################################################\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    solver = tf.train.AdamOptimizer()\n",
    "    grads = solver.compute_gradients(loss)\n",
    "    grads = [(tf.clip_by_norm(g, clip_norm=10), v) for g, v in grads]\n",
    "    train_op = solver.apply_gradients(grads)\n",
    "\n",
    "##################################################################\n",
    "# Logging\n",
    "##################################################################\n",
    "with tf.name_scope(\"Logging\"):\n",
    "    recon_loss_ph = tf.placeholder(tf.float32)\n",
    "    kl_loss_ph = tf.placeholder(tf.float32)\n",
    "    loss_ph = tf.placeholder(tf.float32)\n",
    "    audio_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "    tf.summary.scalar(\"Reconstruction_loss\", recon_loss_ph)\n",
    "    tf.summary.scalar(\"KL_loss\", kl_loss_ph)\n",
    "    tf.summary.scalar(\"Loss\", loss_ph)\n",
    "    tf.summary.audio(\"sample_output\", audio_ph, audio_sr)\n",
    "    log_op = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter('./tb/', graph=tf.get_default_graph())\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "#sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "# Run Initialization operations\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "loss_avg = 0.0\n",
    "decay = 0.99\n",
    "time0 = time.time()\n",
    "##################################################################\n",
    "# Optimization loop\n",
    "##################################################################\n",
    "for e in range(n_epochs):\n",
    "    i = 0\n",
    "    for batch in bars:\n",
    "        batch_in = np.reshape(batch, (T, height, width, 1))\n",
    "        kl_an = 1.0#min(1.0, ((e+1)*num_batches) / (2*num_batches))\n",
    "        _,loss_out, kl, recon = sess.run([train_op, loss, kl_loss, recon_loss], feed_dict={X: batch_in, kl_annealing: kl_an})\n",
    "\n",
    "        if (i % log_interval) == 0:\n",
    "            loss_avg = decay*loss_avg + (1-decay)*loss_out\n",
    "            print('\\titer = %d, local_loss (cur) = %f, local_loss (avg) = %f, kl = %f'\n",
    "                % (i, loss_out, loss_avg, kl))\n",
    "            \n",
    "            time_spent = time.time() - time0\n",
    "            print('\\n\\tTotal time elapsed: %f sec. Average time per batch: %f sec\\n' %\n",
    "                (time_spent, time_spent / (i+1)))\n",
    "            #Random samples\n",
    "            z_in = np.random.randn(1, z_dim)\n",
    "            z_rnn_out = np.zeros((1,height,width,1))\n",
    "            first = True\n",
    "            for j in range(T):\n",
    "                samples = sess.run(X_samples, feed_dict={z: np.random.randn(1, z_dim), z_rnn_samples: z_rnn_out})\n",
    "                frames = j + 1\n",
    "                if first:\n",
    "                    frames = 2\n",
    "                z_rnn_out = samples.reshape((frames, height, width, 1))\n",
    "                if first:\n",
    "                    z_rnn_out = np.expand_dims(z_rnn_out[-1,:,:,:], axis=0)\n",
    "                    first = False\n",
    "            samples = samples.reshape((num_timesteps*T, note_range))\n",
    "            thresh_S = samples >= 0.5\n",
    "            \n",
    "            pm_out = piano_roll_to_pretty_midi(thresh_S.T * 127, fs=fs)\n",
    "            midi_out = './tb/audio/test002_{0}.mid'.format(datetime.now().strftime(\"%Y.%m.%d.%H:%M:%S\"))\n",
    "            wav_out = './tb/audio/test002_{0}.wav'.format(datetime.now().strftime(\"%Y.%m.%d.%H:%M:%S\"))\n",
    "            audio = pm_out.synthesize() \n",
    "            audio = audio.reshape((1, len(audio)))\n",
    "            #Write out logs\n",
    "            summary = sess.run(log_op, feed_dict={recon_loss_ph: np.mean(recon), kl_loss_ph: np.mean(kl),\n",
    "                                                 loss_ph: loss_out, audio_ph: audio})\n",
    "            writer.add_summary(summary, i)\n",
    "        \n",
    "        if (i % snapshot_interval) == 0:\n",
    "            saver.save(sess, checkpoint_file % i)\n",
    "\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
